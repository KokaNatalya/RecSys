{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from random import randint\n",
    "import keras \n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Рекомендательная система фильмов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "модель написана на основе данных Kion, для соревнования RecSys Course Competition от МТС на Open Data Science.\n",
    "\n",
    "выполнена с помощью нейронной сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df=pd.read_csv('RecSys/users.csv', \n",
    "                     dtype={'kids_flg':np.int8})\n",
    "\n",
    "items_df = pd.read_csv(\"RecSys/items.csv\")\n",
    "\n",
    "interactions_df = pd.read_csv('RecSys/interactions.csv', \n",
    "                              parse_dates=['last_watch_dt'], \n",
    "                              dtype={'total_dur':np.int16})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "посмотрим данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>sex</th>\n",
       "      <th>kids_flg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>973171</td>\n",
       "      <td>age_25_34</td>\n",
       "      <td>income_60_90</td>\n",
       "      <td>М</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>962099</td>\n",
       "      <td>age_18_24</td>\n",
       "      <td>income_20_40</td>\n",
       "      <td>М</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1047345</td>\n",
       "      <td>age_45_54</td>\n",
       "      <td>income_40_60</td>\n",
       "      <td>Ж</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id        age        income sex  kids_flg\n",
       "0   973171  age_25_34  income_60_90   М         1\n",
       "1   962099  age_18_24  income_20_40   М         0\n",
       "2  1047345  age_45_54  income_40_60   Ж         0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 840197 entries, 0 to 840196\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   user_id   840197 non-null  int64 \n",
      " 1   age       826102 non-null  object\n",
      " 2   income    825421 non-null  object\n",
      " 3   sex       826366 non-null  object\n",
      " 4   kids_flg  840197 non-null  int8  \n",
      "dtypes: int64(1), int8(1), object(3)\n",
      "memory usage: 26.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>content_type</th>\n",
       "      <th>title</th>\n",
       "      <th>title_orig</th>\n",
       "      <th>release_year</th>\n",
       "      <th>genres</th>\n",
       "      <th>countries</th>\n",
       "      <th>for_kids</th>\n",
       "      <th>age_rating</th>\n",
       "      <th>studios</th>\n",
       "      <th>directors</th>\n",
       "      <th>actors</th>\n",
       "      <th>description</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10711</td>\n",
       "      <td>film</td>\n",
       "      <td>Поговори с ней</td>\n",
       "      <td>Hable con ella</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>драмы, зарубежные, детективы, мелодрамы</td>\n",
       "      <td>Испания</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Педро Альмодовар</td>\n",
       "      <td>Адольфо Фернандес, Ана Фернандес, Дарио Гранди...</td>\n",
       "      <td>Мелодрама легендарного Педро Альмодовара «Пого...</td>\n",
       "      <td>Поговори, ней, 2002, Испания, друзья, любовь, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2508</td>\n",
       "      <td>film</td>\n",
       "      <td>Голые перцы</td>\n",
       "      <td>Search Party</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>зарубежные, приключения, комедии</td>\n",
       "      <td>США</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Скот Армстронг</td>\n",
       "      <td>Адам Палли, Брайан Хаски, Дж.Б. Смув, Джейсон ...</td>\n",
       "      <td>Уморительная современная комедия на популярную...</td>\n",
       "      <td>Голые, перцы, 2014, США, друзья, свадьбы, прео...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10716</td>\n",
       "      <td>film</td>\n",
       "      <td>Тактическая сила</td>\n",
       "      <td>Tactical Force</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>криминал, зарубежные, триллеры, боевики, комедии</td>\n",
       "      <td>Канада</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Адам П. Калтраро</td>\n",
       "      <td>Адриан Холмс, Даррен Шалави, Джерри Вассерман,...</td>\n",
       "      <td>Профессиональный рестлер Стив Остин («Все или ...</td>\n",
       "      <td>Тактическая, сила, 2011, Канада, бандиты, ганг...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id content_type             title      title_orig  release_year  \\\n",
       "0    10711         film    Поговори с ней  Hable con ella        2002.0   \n",
       "1     2508         film       Голые перцы    Search Party        2014.0   \n",
       "2    10716         film  Тактическая сила  Tactical Force        2011.0   \n",
       "\n",
       "                                             genres countries  for_kids  \\\n",
       "0           драмы, зарубежные, детективы, мелодрамы   Испания       NaN   \n",
       "1                  зарубежные, приключения, комедии       США       NaN   \n",
       "2  криминал, зарубежные, триллеры, боевики, комедии    Канада       NaN   \n",
       "\n",
       "   age_rating studios         directors  \\\n",
       "0        16.0     NaN  Педро Альмодовар   \n",
       "1        16.0     NaN    Скот Армстронг   \n",
       "2        16.0     NaN  Адам П. Калтраро   \n",
       "\n",
       "                                              actors  \\\n",
       "0  Адольфо Фернандес, Ана Фернандес, Дарио Гранди...   \n",
       "1  Адам Палли, Брайан Хаски, Дж.Б. Смув, Джейсон ...   \n",
       "2  Адриан Холмс, Даррен Шалави, Джерри Вассерман,...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Мелодрама легендарного Педро Альмодовара «Пого...   \n",
       "1  Уморительная современная комедия на популярную...   \n",
       "2  Профессиональный рестлер Стив Остин («Все или ...   \n",
       "\n",
       "                                            keywords  \n",
       "0  Поговори, ней, 2002, Испания, друзья, любовь, ...  \n",
       "1  Голые, перцы, 2014, США, друзья, свадьбы, прео...  \n",
       "2  Тактическая, сила, 2011, Канада, бандиты, ганг...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15963 entries, 0 to 15962\n",
      "Data columns (total 14 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   item_id       15963 non-null  int64  \n",
      " 1   content_type  15963 non-null  object \n",
      " 2   title         15963 non-null  object \n",
      " 3   title_orig    11218 non-null  object \n",
      " 4   release_year  15865 non-null  float64\n",
      " 5   genres        15963 non-null  object \n",
      " 6   countries     15926 non-null  object \n",
      " 7   for_kids      566 non-null    float64\n",
      " 8   age_rating    15961 non-null  float64\n",
      " 9   studios       1065 non-null   object \n",
      " 10  directors     14454 non-null  object \n",
      " 11  actors        13344 non-null  object \n",
      " 12  description   15961 non-null  object \n",
      " 13  keywords      15540 non-null  object \n",
      "dtypes: float64(3), int64(1), object(10)\n",
      "memory usage: 1.7+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>last_watch_dt</th>\n",
       "      <th>total_dur</th>\n",
       "      <th>watched_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>176549</td>\n",
       "      <td>9506</td>\n",
       "      <td>2021-05-11</td>\n",
       "      <td>4250</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>699317</td>\n",
       "      <td>1659</td>\n",
       "      <td>2021-05-29</td>\n",
       "      <td>8317</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>656683</td>\n",
       "      <td>7107</td>\n",
       "      <td>2021-05-09</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id last_watch_dt  total_dur  watched_pct\n",
       "0   176549     9506    2021-05-11       4250         72.0\n",
       "1   699317     1659    2021-05-29       8317        100.0\n",
       "2   656683     7107    2021-05-09         10          0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5476251 entries, 0 to 5476250\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Dtype         \n",
      "---  ------         -----         \n",
      " 0   user_id        int64         \n",
      " 1   item_id        int64         \n",
      " 2   last_watch_dt  datetime64[ns]\n",
      " 3   total_dur      int16         \n",
      " 4   watched_pct    float64       \n",
      "dtypes: datetime64[ns](1), float64(1), int16(1), int64(2)\n",
      "memory usage: 177.6 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfs=[users_df, items_df, interactions_df]\n",
    "\n",
    "for i in dfs:\n",
    "    display(i.head(3))\n",
    "    display(i.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "есть много фичей перечисленных через запятую, надо будет их распарсить, чтобы сделать вид one-hot, т.к. разные комбинации стран или режиссеров будут увеличивать число столбцов и векторы фильмов с одним и тем же режиссером или страной будут иметь отличающиеся вектора, т.к. списки не будут совпадать полностью"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка фичей юзеров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "категориальные переменные переводим в one-hot вид"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_18_24</th>\n",
       "      <th>age_25_34</th>\n",
       "      <th>age_35_44</th>\n",
       "      <th>age_45_54</th>\n",
       "      <th>age_55_64</th>\n",
       "      <th>age_65_inf</th>\n",
       "      <th>income_0_20</th>\n",
       "      <th>income_150_inf</th>\n",
       "      <th>income_20_40</th>\n",
       "      <th>income_40_60</th>\n",
       "      <th>income_60_90</th>\n",
       "      <th>income_90_150</th>\n",
       "      <th>Ж</th>\n",
       "      <th>М</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>973171</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>962099</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047345</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721985</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704055</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         age_18_24  age_25_34  age_35_44  age_45_54  age_55_64  age_65_inf  \\\n",
       "user_id                                                                      \n",
       "973171           0          1          0          0          0           0   \n",
       "962099           1          0          0          0          0           0   \n",
       "1047345          0          0          0          1          0           0   \n",
       "721985           0          0          0          1          0           0   \n",
       "704055           0          0          1          0          0           0   \n",
       "\n",
       "         income_0_20  income_150_inf  income_20_40  income_40_60  \\\n",
       "user_id                                                            \n",
       "973171             0               0             0             0   \n",
       "962099             0               0             1             0   \n",
       "1047345            0               0             0             1   \n",
       "721985             0               0             1             0   \n",
       "704055             0               0             0             0   \n",
       "\n",
       "         income_60_90  income_90_150  Ж  М  0  1  \n",
       "user_id                                           \n",
       "973171              1              0  0  1  0  1  \n",
       "962099              0              0  0  1  1  0  \n",
       "1047345             0              0  1  0  1  0  \n",
       "721985              0              0  1  0  1  0  \n",
       "704055              1              0  1  0  1  0  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_categories=[\"age\", \"income\", \"sex\", \"kids_flg\"]\n",
    "\n",
    "ohe_users = users_df['user_id']\n",
    "for i in users_categories:\n",
    "    ohe_df=pd.get_dummies(users_df[i])\n",
    "    ohe_users=pd.concat([ohe_users, ohe_df], axis=1)\n",
    "\n",
    "ohe_users = ohe_users.set_index('user_id')\n",
    "ohe_users.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка фичей фильмов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "фичи в которых идет перечисление через запятую приводим к списку и приводим к one-hot виду"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_ohe(df, col):\n",
    "    \n",
    "    items_df[col]=items_df[col].fillna('unknown')\n",
    "    items_df[col]=items_df[col].str.split(',')\n",
    "    \n",
    "    mlb = MultiLabelBinarizer(sparse_output=True)\n",
    "    df = pd.DataFrame.sparse.from_spmatrix(\n",
    "             mlb.fit_transform(items_df.pop(col)),\n",
    "             index=items_df.index,\n",
    "             columns=mlb.classes_)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "объединим года в категориальные переменные. т.к. начиная в 80х снимать стали больше дробим по 10 лет. \n",
    "\n",
    "группа \"после 2020\" будет небольшая по объему, но важна для аудитории \"любителей новинок\", поэтому смешивать их даже с группой 2015 г. не стоит "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_df['release_year']=items_df['release_year'].fillna(0) # заполним пропуски на условное обозначение\n",
    "items_df['release_year']=items_df['release_year'].astype('int16')\n",
    "\n",
    "items_df['year_group'] = pd.cut(items_df['release_year'], [0, 1800,1940,1960,1980,1990,2000,2010,2020,2030],\n",
    "                               labels=['year_unknown',\n",
    "                                       'before_1940',\n",
    "                                       '1940_1960',\n",
    "                                       '1960_1980',\n",
    "                                       '1980_1990',\n",
    "                                       '1990_2000',\n",
    "                                       '2000_2010',\n",
    "                                       '2010_2020',\n",
    "                                       'after_2020'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "собираем в один датафрейм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>film</th>\n",
       "      <th>series</th>\n",
       "      <th>year_unknown</th>\n",
       "      <th>before_1940</th>\n",
       "      <th>1940_1960</th>\n",
       "      <th>1960_1980</th>\n",
       "      <th>1980_1990</th>\n",
       "      <th>1990_2000</th>\n",
       "      <th>2000_2010</th>\n",
       "      <th>2010_2020</th>\n",
       "      <th>...</th>\n",
       "      <th>Яннике Систад Якобсен</th>\n",
       "      <th>Янус Мец</th>\n",
       "      <th>Ярив Хоровиц</th>\n",
       "      <th>Ярон Зильберман</th>\n",
       "      <th>Ярополк Лапшин</th>\n",
       "      <th>Ярослав Лупий</th>\n",
       "      <th>Ярроу Чейни</th>\n",
       "      <th>Ясина Сезар</th>\n",
       "      <th>Ясуоми Умэцу</th>\n",
       "      <th>сения Завьялова</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10711</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2508</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10716</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7868</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16268</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 10079 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         film  series  year_unknown  before_1940  1940_1960  1960_1980  \\\n",
       "item_id                                                                  \n",
       "10711       1       0             0            0          0          0   \n",
       "2508        1       0             0            0          0          0   \n",
       "10716       1       0             0            0          0          0   \n",
       "7868        1       0             0            0          0          0   \n",
       "16268       1       0             0            0          0          1   \n",
       "\n",
       "         1980_1990  1990_2000  2000_2010  2010_2020  ...  \\\n",
       "item_id                                              ...   \n",
       "10711            0          0          1          0  ...   \n",
       "2508             0          0          0          1  ...   \n",
       "10716            0          0          0          1  ...   \n",
       "7868             0          0          0          1  ...   \n",
       "16268            0          0          0          0  ...   \n",
       "\n",
       "         Яннике Систад Якобсен  Янус Мец  Ярив Хоровиц  Ярон Зильберман  \\\n",
       "item_id                                                                   \n",
       "10711                        0         0             0                0   \n",
       "2508                         0         0             0                0   \n",
       "10716                        0         0             0                0   \n",
       "7868                         0         0             0                0   \n",
       "16268                        0         0             0                0   \n",
       "\n",
       "         Ярополк Лапшин  Ярослав Лупий  Ярроу Чейни  Ясина Сезар  \\\n",
       "item_id                                                            \n",
       "10711                 0              0            0            0   \n",
       "2508                  0              0            0            0   \n",
       "10716                 0              0            0            0   \n",
       "7868                  0              0            0            0   \n",
       "16268                 0              0            0            0   \n",
       "\n",
       "         Ясуоми Умэцу  сения Завьялова  \n",
       "item_id                                 \n",
       "10711               0                0  \n",
       "2508                0                0  \n",
       "10716               0                0  \n",
       "7868                0                0  \n",
       "16268               0                0  \n",
       "\n",
       "[5 rows x 10079 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genres = pd.DataFrame()\n",
    "countries = pd.DataFrame()\n",
    "directors = pd.DataFrame()\n",
    "studios = pd.DataFrame()\n",
    "\n",
    "items_categories=['content_type', 'year_group', 'for_kids', \n",
    "                  'age_rating']\n",
    "\n",
    "ohe_items = items_df['item_id']\n",
    "for i in items_categories:\n",
    "    ohe_df=pd.get_dummies(items_df[i])\n",
    "    ohe_items=pd.concat([ohe_items, ohe_df], axis=1)\n",
    "\n",
    "ohe_items=pd.concat([ohe_items, to_ohe(genres, 'genres'),\n",
    "                     to_ohe(studios, 'studios'),\n",
    "                     to_ohe(countries, 'countries'),\n",
    "                     to_ohe(directors, 'directors')], axis=1)\n",
    "ohe_items = ohe_items.set_index('item_id')\n",
    "\n",
    "ohe_items.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка датафрейма просмотров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "оставим только просмотры более чем на 50%, т.к. если пользователь не досморел фильм хотя бы до половины, то вряд-ли он ему понравился.\n",
    "\n",
    "также удалим непопулярные фильмы, холодных и еле теплых юзеров (посмотревших менее 10 фильмов), т.к. их предпочтения пока не ясны, что может создавать помехи на обучении."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество пользователей до чистки: 962179\n",
      "Количество фильмов до чистки: 15706\n",
      "\n",
      "\n",
      "Количество пользователей после чистки: 56955\n",
      "Количество фильмов после чистки: 6252\n"
     ]
    }
   ],
   "source": [
    "print(f\"Количество пользователей до чистки: {interactions_df['user_id'].nunique()}\")\n",
    "print(f\"Количество фильмов до чистки: {interactions_df['item_id'].nunique()}\")\n",
    "print('\\n')\n",
    "\n",
    "# оставим только просмотры более чем 50% фильмов\n",
    "interactions_df = interactions_df[interactions_df['watched_pct'] > 50]\n",
    "\n",
    "# оставим пользователей которые посмотрели больше 5 фильмов\n",
    "active_users = []\n",
    "\n",
    "c = Counter(interactions_df['user_id'])\n",
    "for user_id, watches in c.most_common():\n",
    "    if watches > 10:\n",
    "        active_users.append(user_id)\n",
    "\n",
    "# оставим фильмы, которые посмотрели больше 10 пользователей\n",
    "active_items = []\n",
    "\n",
    "c = Counter(interactions_df['item_id'])\n",
    "for item_id, watches in c.most_common():\n",
    "    if watches > 10:\n",
    "        active_items.append(item_id)\n",
    "\n",
    "interactions_df = interactions_df[interactions_df['user_id'].isin(active_users)]\n",
    "interactions_df = interactions_df[interactions_df['item_id'].isin(active_items)]\n",
    "\n",
    "print(f\"Количество пользователей после чистки: {interactions_df['user_id'].nunique()}\")\n",
    "print(f\"Количество фильмов после чистки: {interactions_df['item_id'].nunique()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После фильтрации некоторые юзеры или фильтры есть в датасете просмотров, но отсутствуют в датасетах юзеров или фильмов и наоборот. Поэтому оставим user_id и item_id, которые есть во всех датасетах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "количество уникальных пользователей = 47270\n",
      "количество уникальных фильмов = 6252\n"
     ]
    }
   ],
   "source": [
    "uniq_users = set(interactions_df['user_id'].unique()).intersection(set(ohe_users.index.unique()))\n",
    "uniq_items = set(interactions_df['item_id'].unique()).intersection(set(ohe_items.index.unique()))\n",
    "\n",
    "print(f'количество уникальных пользователей = {len(uniq_users)}')\n",
    "print(f'количество уникальных фильмов = {len(uniq_items)}')\n",
    "\n",
    "interactions_df=interactions_df[interactions_df['user_id'].isin(uniq_users)]\n",
    "interactions_df=interactions_df[interactions_df['item_id'].isin(uniq_items)]\n",
    "ohe_users = ohe_users[ohe_users.index.isin(uniq_users)]\n",
    "ohe_items = ohe_items[ohe_items.index.isin(uniq_items)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "сделаем матрицу просмотров. если пользователь смотрел фильм - 1, не смотрел - 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": 
    "interactions_pivot = interactions_df.pivot_table(index='user_id', \n",
    "                                                 columns='item_id', \n",
    "                                                 values='last_watch_dt', 
                                                      aggfunc='count', \n",
    "                                                 fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Triplet loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмем векторы пользователя, просмотренного (positive) и непросмотренного (negative) фильмов и посчитаем расстояния между веторами пользователя и фильмов.\n",
    "Значением функции потерь будет разность между расстоянием с просмотренным и с непросмотренным фильмом.\n",
    "\n",
    "Задача лосса максимально уменьшить расстояние между векторами пользователя и \"позитивного\" фильма и максимально отдалить вектора пользователя и \"негативного\" фильма, чтобы разница между 1 и 2 расстояниями была положительная т.е. сходство вектора пользователя и вектора просмотренного фильма сильнее. \n",
    "\n",
    "Для этого используется гиперпараметр **alpha**, который должен сделать лосс положительным когда 1 и 2 расстояния равны (без него он был бы равен 0 и обучение прекратилось), т.к. мы хотим чтобы расстояние до просмотреноого фильма было меньше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEN_VECTORS=128 # размер векторов на входе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss(y_true, y_pred, n=LEN_VECTORS, alpha=0.4):\n",
    "    \n",
    "    user = y_pred[:, 0:n]\n",
    "    positive = y_pred[:, n:n*2]\n",
    "    negative = y_pred[:, n*2:n*3]\n",
    "\n",
    "    # считаем расстояния \n",
    "    pos_dist = K.sum(K.square(user - positive), axis=1)\n",
    "    neg_dist = K.sum(K.square(user - negative), axis=1)\n",
    "\n",
    "    # считаем лосс\n",
    "    basic_loss = pos_dist - neg_dist + alpha\n",
    "    loss = K.maximum(basic_loss, 0.0) # возвращаем ноль, если лосс отрицательный\n",
    " \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### генератор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(items, users, interactions, batch_size=1024):\n",
    "    while True:\n",
    "        user = []\n",
    "        uid_interaction = []\n",
    "        pos = []\n",
    "        neg = []\n",
    "        for i in range(batch_size):\n",
    "            #id юзера и фильмов\n",
    "            user_i = np.random.choice(interactions.index)\n",
    "            #берем индексы фильмов выбранного пользователя\n",
    "            pos_i = np.random.choice((interactions.loc[user_i].index) \n",
    "                                     #которые были просмотрены, имеют 1 в таблице просмотров\n",
    "                                     .where(pd.Series(interactions.loc[user_i]).values==1) \n",
    "                                      #убираем из списка индексы непросмотренных\n",
    "                                     .dropna().astype('uint64')) \n",
    "            \n",
    "            neg_i = np.random.choice((interactions.loc[user_i].index)\n",
    "                                      #фильмы, которые не были просмотрены\n",
    "                                      .where(pd.Series(interactions.loc[user_i]).values==0) \n",
    "                                      .dropna().astype('uint64'))\n",
    "            \n",
    "            user.append(users.loc[user_i])\n",
    "            # вектор айтемов, с которыми юзер взаимодействовал\n",
    "            uid_interaction.append(interactions.loc[user_i])\n",
    "            # фичи хорошего айтема\n",
    "            pos.append(items.loc[pos_i])\n",
    "            # фичи плохого айтема\n",
    "            neg.append(items.loc[neg_i])\n",
    "        \n",
    "        yield [np.array(user), np.array(uid_interaction), np.array(pos), np.array(neg)], [np.array(user), np.array(uid_interaction)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Соберем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEN_VECTORS: 128\n",
      "FILM_MODEL_SHAPE: 10079\n",
      "USER_MODEL_SHAPE: 16\n",
      "INTERACTION_MODEL_SHAPE: 6249\n"
     ]
    }
   ],
   "source": [
    "# в датасетах есть столбец user_id/item_id, помним, что он не является фичей для обучения!\n",
    "FILM_MODEL_SHAPE = (ohe_items.shape[1]) \n",
    "USER_MODEL_SHAPE = (ohe_users.shape[1])\n",
    "\n",
    "INTERACTION_MODEL_SHAPE = (interactions_pivot.shape[1])\n",
    "\n",
    "print(f\"LEN_VECTORS: {LEN_VECTORS}\")\n",
    "print(f\"FILM_MODEL_SHAPE: {FILM_MODEL_SHAPE}\")\n",
    "print(f\"USER_MODEL_SHAPE: {USER_MODEL_SHAPE}\")\n",
    "print(f\"INTERACTION_MODEL_SHAPE: {INTERACTION_MODEL_SHAPE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# модель для подготовки векторов фильмов\n",
    "def film_model(n_factors=LEN_VECTORS, regularization = keras.regularizers.l2(1e-6)):\n",
    "    # входной слой\n",
    "    inp = keras.layers.Input(shape=FILM_MODEL_SHAPE)\n",
    "    \n",
    "    layer_1 = keras.layers.Dense(LEN_VECTORS, activation='elu', use_bias=False,\n",
    "                               kernel_regularizer=regularization,\n",
    "                               activity_regularizer=regularization)(inp)\n",
    "\n",
    "    layer_2 = keras.layers.Dense(LEN_VECTORS, activation='elu', use_bias=False,\n",
    "                             kernel_regularizer=regularization,\n",
    "                             activity_regularizer=regularization)(layer_1)\n",
    "   \n",
    "    # делаем residual connection, чтобы градиенты не затухали во время обучения\n",
    "    add = keras.layers.Add()([layer_1, layer_2])\n",
    "    \n",
    "    # выходной слой\n",
    "    out = keras.layers.Dense(LEN_VECTORS, activation='linear', use_bias=False,\n",
    "                             kernel_regularizer=regularization,\n",
    "                             activity_regularizer=regularization)(add)\n",
    "    \n",
    "    return keras.models.Model(inp, out)\n",
    "\n",
    "# модель для подготовки векторов пользователей\n",
    "def user_model(n_factors=LEN_VECTORS, regularization = keras.regularizers.l2(1e-6)):\n",
    "    \n",
    "    # входной слой для вектора фичей юзера (из ohe_users)\n",
    "    inp = keras.layers.Input(shape=USER_MODEL_SHAPE)\n",
    "    # входной слой для вектора просмотров (из iteractions_pivot)\n",
    "    inp_interaction = keras.layers.Input(shape=INTERACTION_MODEL_SHAPE)\n",
    "\n",
    "    layer_1 = keras.layers.Dense(LEN_VECTORS, activation='elu', use_bias=False,\n",
    "                                 kernel_regularizer=regularization,\n",
    "                                 activity_regularizer=regularization)(inp)\n",
    "\n",
    "    layer_1_interaction = keras.layers.Dense(LEN_VECTORS, activation='elu', use_bias=False,\n",
    "                                 kernel_regularizer=regularization,\n",
    "                                 activity_regularizer=regularization)(inp_interaction)\n",
    "\n",
    "    layer_2 = keras.layers.Dense(LEN_VECTORS, activation='elu', use_bias=False,\n",
    "                                 kernel_regularizer=regularization,\n",
    "                                 activity_regularizer=regularization)(layer_1)\n",
    "\n",
    "    add = keras.layers.Add()([layer_1, layer_2])\n",
    "    \n",
    "    concat = keras.layers.Concatenate()([add, layer_1_interaction])\n",
    "    \n",
    "    # выходной слой\n",
    "    out = keras.layers.Dense(LEN_VECTORS, activation='linear', use_bias=False,\n",
    "                             kernel_regularizer=regularization,\n",
    "                             activity_regularizer=regularization)(concat)\n",
    "    \n",
    "    return keras.models.Model([inp, inp_interaction], out)\n",
    "\n",
    "# инициализируем модели юзера и фильма\n",
    "i2v = film_model()\n",
    "u2v = user_model()\n",
    "\n",
    "# вход для вектора фичей юзера (из ohe_users)\n",
    "user_in = keras.layers.Input(shape=USER_MODEL_SHAPE)\n",
    "# вход для вектора просмотра юзера (из interactions_pivot)\n",
    "interaction_in = keras.layers.Input(shape=INTERACTION_MODEL_SHAPE)\n",
    "\n",
    "# вход для векторов фильмов\n",
    "pos_in = keras.layers.Input(shape=FILM_MODEL_SHAPE)\n",
    "neg_in = keras.layers.Input(shape=FILM_MODEL_SHAPE)\n",
    "\n",
    "# вектор пользователя\n",
    "user = u2v([user_in, interaction_in])\n",
    "# вектора фильмов\n",
    "pos = i2v(pos_in)\n",
    "neg = i2v(neg_in)\n",
    "\n",
    "# конкатенируем векторы\n",
    "res = keras.layers.Concatenate(name=\"concat_ancor_pos_neg\")([user, pos, neg])\n",
    "\n",
    "model = keras.models.Model([user_in, interaction_in, pos_in, neg_in], res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "посмотрим архитектуру моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_14\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_32 (InputLayer)          [(None, 16)]         0           []                               \n",
      "                                                                                                  \n",
      " input_33 (InputLayer)          [(None, 6249)]       0           []                               \n",
      "                                                                                                  \n",
      " input_34 (InputLayer)          [(None, 10079)]      0           []                               \n",
      "                                                                                                  \n",
      " input_35 (InputLayer)          [(None, 10079)]      0           []                               \n",
      "                                                                                                  \n",
      " model_13 (Functional)          (None, 128)          851072      ['input_32[0][0]',               \n",
      "                                                                  'input_33[0][0]']               \n",
      "                                                                                                  \n",
      " model_12 (Functional)          (None, 128)          1322880     ['input_34[0][0]',               \n",
      "                                                                  'input_35[0][0]']               \n",
      "                                                                                                  \n",
      " concat_ancor_pos_neg (Concaten  (None, 384)         0           ['model_13[0][0]',               \n",
      " ate)                                                             'model_12[0][0]',               \n",
      "                                                                  'model_12[1][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,173,952\n",
      "Trainable params: 2,173,952\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_13\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_30 (InputLayer)          [(None, 16)]         0           []                               \n",
      "                                                                                                  \n",
      " dense_31 (Dense)               (None, 128)          2048        ['input_30[0][0]']               \n",
      "                                                                                                  \n",
      " dense_33 (Dense)               (None, 128)          16384       ['dense_31[0][0]']               \n",
      "                                                                                                  \n",
      " input_31 (InputLayer)          [(None, 6249)]       0           []                               \n",
      "                                                                                                  \n",
      " add_9 (Add)                    (None, 128)          0           ['dense_31[0][0]',               \n",
      "                                                                  'dense_33[0][0]']               \n",
      "                                                                                                  \n",
      " dense_32 (Dense)               (None, 128)          799872      ['input_31[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 256)          0           ['add_9[0][0]',                  \n",
      "                                                                  'dense_32[0][0]']               \n",
      "                                                                                                  \n",
      " dense_34 (Dense)               (None, 128)          32768       ['concatenate_4[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 851,072\n",
      "Trainable params: 851,072\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_12\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_29 (InputLayer)          [(None, 10079)]      0           []                               \n",
      "                                                                                                  \n",
      " dense_28 (Dense)               (None, 128)          1290112     ['input_29[0][0]']               \n",
      "                                                                                                  \n",
      " dense_29 (Dense)               (None, 128)          16384       ['dense_28[0][0]']               \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 128)          0           ['dense_28[0][0]',               \n",
      "                                                                  'dense_29[0][0]']               \n",
      "                                                                                                  \n",
      " dense_30 (Dense)               (None, 128)          16384       ['add_8[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,322,880\n",
      "Trainable params: 1,322,880\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(model.summary())\n",
    "display(u2v.summary())\n",
    "display(i2v.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'recsys'\n",
    "\n",
    "# логируем процесс обучения в тензорборд\n",
    "t_board = keras.callbacks.TensorBoard(log_dir=f'runs/{model_name}')\n",
    "\n",
    "# уменьшаем learning_rate, если лосс не уменьшается в течение двух эпох\n",
    "decay = keras.callbacks.ReduceLROnPlateau(monitor='loss', patience=2, factor=0.8, verbose=1)\n",
    "\n",
    "# сохраняем модель после каждой эпохи, если лосс уменьшился\n",
    "check = keras.callbacks.ModelCheckpoint(filepath=model_name + '/epoch{epoch}-{loss:.2f}.h5', monitor=\"loss\")\n",
    "\n",
    "adam = tf.keras.optimizers.Adam(lr=0.001)\n",
    "model.compile(loss=triplet_loss, optimizer=adam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "определим зерно датчика случайных чисел для воспроизводимости модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED=200\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "100/100 [==============================] - 1620s 16s/step - loss: 0.2311 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 1587s 16s/step - loss: 0.1649 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 1693s 17s/step - loss: 0.1689 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 1627s 16s/step - loss: 0.1474 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 1845s 18s/step - loss: 0.1467 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 1514s 15s/step - loss: 0.1553 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 1524s 15s/step - loss: 0.1393 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 1542s 15s/step - loss: 0.1297 - lr: 0.0010\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 1602s 16s/step - loss: 0.1286 - lr: 0.0010\n",
      "Epoch 10/30\n",
      " 87/100 [=========================>....] - ETA: 3:23 - loss: 0.1289"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-79-1775a52013c2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m model.fit(generator(items=ohe_items,\n\u001b[0m\u001b[0;32m      2\u001b[0m                     \u001b[0musers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mohe_users\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                     \u001b[0minteractions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minteractions_pivot\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                     batch_size=64), \n\u001b[0;32m      5\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1214\u001b[0m                 _r=1):\n\u001b[0;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1217\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 910\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    940\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    941\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 942\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    943\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3128\u001b[0m       (graph_function,\n\u001b[0;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3130\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1958\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1959\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     60\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(generator(items=ohe_items,\n",
    "                    users=ohe_users, \n",
    "                    interactions=interactions_pivot,\n",
    "                    batch_size=64), \n",
    "          steps_per_epoch=100, \n",
    "          epochs=30, \n",
    "          initial_epoch=0,\n",
    "          callbacks=[decay, t_board, check]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Порекомендуем"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "получаем данные о пользователе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# берем рандомного юзера\n",
    "rand_uid = np.random.choice(list(ohe_users.index))\n",
    "\n",
    "# фичи юзера и вектор его просмотров\n",
    "user_features = ohe_users.loc[rand_uid]\n",
    "user_interaction = interactions_pivot.loc[rand_uid]\n",
    "\n",
    "# вектор юзера\n",
    "user_vec = u2v.predict([np.array(user_features).reshape(1, -1), \n",
    "                        np.array(user_interaction).reshape(1, -1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "получаем данные по всем фильмам и рекомендуем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5172                               Русская симфония\n",
       "5845                            Неуловимые мстители\n",
       "6856                                       Чертенок\n",
       "7392                              Тор: Царство тьмы\n",
       "7493                           Афера по-голливудски\n",
       "8302          Детектив на миллион. Жертвы искусства\n",
       "9506     Эльдорадо: часть 1. В поисках Храма Солнца\n",
       "10062             Алые паруса (с тифлокомментарием)\n",
       "10811                       Упражнения в прекрасном\n",
       "15828                            Три шага к рельефу\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# получаем фичи всех айтемов\n",
    "films_features = ohe_items.to_numpy()\n",
    "# получаем векторы всех айтемов\n",
    "films_vecs = i2v.predict(films_features)\n",
    "\n",
    "# считаем расстояния\n",
    "dists = cosine_similarity(user_vec, films_vecs)\n",
    "\n",
    "# id рекомендаций\n",
    "top10_films = np.argsort(dists, axis=1)[0][:10]\n",
    "\n",
    "# названия рекомендаций\n",
    "recommended_titles = items_df.loc[items_df['item_id'].isin(top10_films)]['title']\n",
    "recommended_titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "сравним с просмотренными фильмами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "345                                       Невидимый гость\n",
       "349     [4К] Пещеры острова Макатеа. Французская Полин...\n",
       "435                                       Тёмное наследие\n",
       "557                      [4К] Природное богатство Корсики\n",
       "696                                  Путешествие в Италию\n",
       "1127                                                Койот\n",
       "1208                                            Коллекция\n",
       "1360                                      Нас не догонишь\n",
       "1383                                    Дитя человеческое\n",
       "1401                                          Прости меня\n",
       "1436                                            Шах и мат\n",
       "1707                                          Привет-пока\n",
       "1717                                  Последние любовники\n",
       "1822                             Пиковая дама: Зазеркалье\n",
       "2289                                            Лис и пёс\n",
       "2437                                     Ультраамериканцы\n",
       "2508                                Только в мьюзик-холле\n",
       "2543                                   Афера по-английски\n",
       "2605                                 Освобождение: Прорыв\n",
       "2700                                         Дело Собчака\n",
       "2760                                     Крикуны 2: Охота\n",
       "2847                                              День до\n",
       "3100                                       Секрет счастья\n",
       "3739                                             Адмиралъ\n",
       "3750                                             Туристас\n",
       "3781            [4К] Подводные сокровища Ислас-де-ла-Баия\n",
       "3906                             Каникулы строгого режима\n",
       "3914                         Высоцкий. Спасибо, что живой\n",
       "3941                                           Супергерои\n",
       "4356                                  Займись своим делом\n",
       "4532                    [4К] Легендарные крушения Корсики\n",
       "4570                                     Прикончи их всех\n",
       "4655                                                 Беда\n",
       "4846                                     Зеленая перчатка\n",
       "4996      Собаки, кошки и другие любимцы - начальный курс\n",
       "5051                                      Ягуар. Гондурас\n",
       "5210                             Добро пожаловать к Райли\n",
       "5645                                            Леди Бёрд\n",
       "5798    Наскальная живопись острова Мисоол. Западное П...\n",
       "5916                                             Его дочь\n",
       "5943                                  За пропастью во ржи\n",
       "6139                                         Небеременная\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "films_viewed = np.where(interactions_pivot.loc[rand_uid] > 0)\n",
    "viewed_list = items_df.loc[films_viewed]['title']\n",
    "viewed_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "в рекомендациях также как и в просмотренныех фильмах есть приклюения, боевики и документальные фильмы, что довольно неплохо отражает предпочтения пользователя."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
